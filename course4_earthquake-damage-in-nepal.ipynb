{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fd101a",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>4 Earthquake Damage in Nepal</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42111212",
   "metadata": {},
   "source": [
    "<font size=\"+2\"><strong>4.5 Earthquake Damage in Kavrepalanchok ðŸ‡³ðŸ‡µ</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd36ba9",
   "metadata": {},
   "source": [
    "This notebook resumes the most important things learned in the WorldQuant Applied Data Science Lab course 4 - \"Earthquake Damage in Nepal\". It uses the courses' project \"Earthquake Damage in Kavrepalanchok\" since it implements the main ideas learned.\n",
    "\n",
    "In this project, I'll work with data from Open Data Nepal to build a model to predict building damage from the Nepal 2015 Earthquake. I'll work primarily with data from the Gorkha district, with additional examples from Ramechhap. \n",
    "\n",
    "Topics learned in this project:\n",
    "\n",
    "- How to get data by querying a SQL database.\n",
    "- How to build a logistic regression model for classification.\n",
    "- How to build a decision tree model for classification.\n",
    "- How to incorporate ethical considerations into your model building.\n",
    "\n",
    "Imports necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e939d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.utils.validation import check_is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64492ebe",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72065aea",
   "metadata": {},
   "source": [
    "<strong>No-SQL (MongoDB)</strong>:\n",
    "- database â†’ collection â†’ documents\n",
    "- semi-structured data (dictionaries are mutable and can have different keys between them)\n",
    "\n",
    "<strong>SQL database</strong>:\n",
    "- tables organized in rows\n",
    "- structured data (each row needs an entry for each column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb221c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b660f60",
   "metadata": {},
   "source": [
    "### Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34bf4f",
   "metadata": {},
   "source": [
    "Connects to the `nepal.sqlite` database using `ipython-sql`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa051217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the extension 'ipythonsql' to connect to the sql database\n",
    "%load_ext sql\n",
    "\n",
    "# tells ipythonsql the location of the database\n",
    "%sql sqlite:///data/nepal.sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed282981",
   "metadata": {},
   "source": [
    "We can also connect to the same database using `sqlite3` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588365c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/nepal.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e5ab3",
   "metadata": {},
   "source": [
    "There are six common clauses used for querying data:\n",
    "\n",
    "| Clause Name | Definition | \n",
    "| --- | --- | \n",
    "| `SELECT` | Determines which columns to include in the query's result |\n",
    "| `FROM` | Identifies the table from which to query the data from |\n",
    "| `WHERE` | filters data |\n",
    "| `GROUP BY` | groups rows by common values in columns |\n",
    "| `HAVING` | filters out unwanted groups from GROUP BY |\n",
    "| `ORDER BY` | Orders the rows using one or more columns |\n",
    "| `LIMIT` | Outputs the specified number of rows |\n",
    "\n",
    "All clauses may be used together, but `SELECT` and `FROM` are the only required clauses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c75dc",
   "metadata": {},
   "source": [
    "Allows us to check everything stored in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd2c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///data/nepal.sqlite\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>type</th>\n",
       "            <th>name</th>\n",
       "            <th>tbl_name</th>\n",
       "            <th>rootpage</th>\n",
       "            <th>sql</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>table</td>\n",
       "            <td>id_map</td>\n",
       "            <td>id_map</td>\n",
       "            <td>2</td>\n",
       "            <td>CREATE TABLE &quot;id_map&quot; (<br>&quot;household_id&quot; INTEGER,<br>  &quot;building_id&quot; INTEGER,<br>  &quot;vdcmun_id&quot; INTEGER,<br>  &quot;district_id&quot; INTEGER<br>)</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>index</td>\n",
       "            <td>ix_id_map_household_id</td>\n",
       "            <td>id_map</td>\n",
       "            <td>3</td>\n",
       "            <td>CREATE INDEX &quot;ix_id_map_household_id&quot;ON &quot;id_map&quot; (&quot;household_id&quot;)</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>table</td>\n",
       "            <td>building_structure</td>\n",
       "            <td>building_structure</td>\n",
       "            <td>2032</td>\n",
       "            <td>CREATE TABLE &quot;building_structure&quot; (<br>&quot;building_id&quot; INTEGER,<br>  &quot;count_floors_pre_eq&quot; INTEGER,<br>  &quot;count_floors_post_eq&quot; INTEGER,<br>  &quot;age_building&quot; INTEGER,<br>  &quot;plinth_area_sq_ft&quot; INTEGER,<br>  &quot;height_ft_pre_eq&quot; INTEGER,<br>  &quot;height_ft_post_eq&quot; INTEGER,<br>  &quot;land_surface_condition&quot; TEXT,<br>  &quot;foundation_type&quot; TEXT,<br>  &quot;roof_type&quot; TEXT,<br>  &quot;ground_floor_type&quot; TEXT,<br>  &quot;other_floor_type&quot; TEXT,<br>  &quot;position&quot; TEXT,<br>  &quot;plan_configuration&quot; TEXT,<br>  &quot;condition_post_eq&quot; TEXT,<br>  &quot;superstructure&quot; TEXT<br>)</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>index</td>\n",
       "            <td>ix_building_structure_building_id</td>\n",
       "            <td>building_structure</td>\n",
       "            <td>2033</td>\n",
       "            <td>CREATE INDEX &quot;ix_building_structure_building_id&quot;ON &quot;building_structure&quot; (&quot;building_id&quot;)</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>table</td>\n",
       "            <td>building_damage</td>\n",
       "            <td>building_damage</td>\n",
       "            <td>12302</td>\n",
       "            <td>CREATE TABLE &quot;building_damage&quot; (<br>&quot;building_id&quot; INTEGER,<br>  &quot;damage_overall_collapse&quot; TEXT,<br>  &quot;damage_overall_leaning&quot; TEXT,<br>  &quot;damage_overall_adjacent_building_risk&quot; TEXT,<br>  &quot;damage_foundation_severe&quot; TEXT,<br>  &quot;damage_foundation_moderate&quot; TEXT,<br>  &quot;damage_foundation_insignificant&quot; TEXT,<br>  &quot;damage_roof_severe&quot; TEXT,<br>  &quot;damage_roof_moderate&quot; TEXT,<br>  &quot;damage_roof_insignificant&quot; TEXT,<br>  &quot;damage_corner_separation_severe&quot; TEXT,<br>  &quot;damage_corner_separation_moderate&quot; TEXT,<br>  &quot;damage_corner_separation_insignificant&quot; TEXT,<br>  &quot;damage_diagonal_cracking_severe&quot; TEXT,<br>  &quot;damage_diagonal_cracking_moderate&quot; TEXT,<br>  &quot;damage_diagonal_cracking_insignificant&quot; TEXT,<br>  &quot;damage_in_plane_failure_severe&quot; TEXT,<br>  &quot;damage_in_plane_failure_moderate&quot; TEXT,<br>  &quot;damage_in_plane_failure_insignificant&quot; TEXT,<br>  &quot;damage_out_of_plane_failure_severe&quot; TEXT,<br>  &quot;damage_out_of_plane_failure_moderate&quot; TEXT,<br>  &quot;damage_out_of_plane_failure_insignificant&quot; TEXT,<br>  &quot;damage_out_of_plane_failure_walls_ncfr_severe&quot; TEXT,<br>  &quot;damage_out_of_plane_failure_walls_ncfr_moderate&quot; TEXT,<br>  &quot;damage_out_of_plane_failure_walls_ncfr_insignificant&quot; TEXT,<br>  &quot;damage_gable_failure_severe&quot; TEXT,<br>  &quot;damage_gable_failure_moderate&quot; TEXT,<br>  &quot;damage_gable_failure_insignificant&quot; TEXT,<br>  &quot;damage_delamination_failure_severe&quot; TEXT,<br>  &quot;damage_delamination_failure_moderate&quot; TEXT,<br>  &quot;damage_delamination_failure_insignificant&quot; TEXT,<br>  &quot;damage_column_failure_severe&quot; TEXT,<br>  &quot;damage_column_failure_moderate&quot; TEXT,<br>  &quot;damage_column_failure_insignificant&quot; TEXT,<br>  &quot;damage_beam_failure_severe&quot; TEXT,<br>  &quot;damage_beam_failure_moderate&quot; TEXT,<br>  &quot;damage_beam_failure_insignificant&quot; TEXT,<br>  &quot;damage_infill_partition_failure_severe&quot; TEXT,<br>  &quot;damage_infill_partition_failure_moderate&quot; TEXT,<br>  &quot;damage_infill_partition_failure_insignificant&quot; TEXT,<br>  &quot;damage_staircase_severe&quot; TEXT,<br>  &quot;damage_staircase_moderate&quot; TEXT,<br>  &quot;damage_staircase_insignificant&quot; TEXT,<br>  &quot;damage_parapet_severe&quot; TEXT,<br>  &quot;damage_parapet_moderate&quot; TEXT,<br>  &quot;damage_parapet_insignificant&quot; TEXT,<br>  &quot;damage_cladding_glazing_severe&quot; TEXT,<br>  &quot;damage_cladding_glazing_moderate&quot; TEXT,<br>  &quot;damage_cladding_glazing_insignificant&quot; TEXT,<br>  &quot;area_assesed&quot; TEXT,<br>  &quot;damage_grade&quot; TEXT,<br>  &quot;technical_solution_proposed&quot; TEXT,<br>  &quot;has_repair_started&quot; REAL,<br>  &quot;has_damage_foundation&quot; REAL,<br>  &quot;has_damage_roof&quot; REAL,<br>  &quot;has_damage_corner_separation&quot; REAL,<br>  &quot;has_damage_diagonal_cracking&quot; REAL,<br>  &quot;has_damage_in_plane_failure&quot; REAL,<br>  &quot;has_damage_out_of_plane_failure&quot; REAL,<br>  &quot;has_damage_out_of_plane_walls_ncfr_failure&quot; REAL,<br>  &quot;has_damage_gable_failure&quot; REAL,<br>  &quot;has_damage_delamination_failure&quot; REAL,<br>  &quot;has_damage_column_failure&quot; REAL,<br>  &quot;has_damage_beam_failure&quot; REAL,<br>  &quot;has_damage_infill_partition_failure&quot; REAL,<br>  &quot;has_damage_staircase&quot; REAL,<br>  &quot;has_damage_parapet&quot; REAL,<br>  &quot;has_damage_cladding_glazing&quot; REAL,<br>  &quot;has_geotechnical_risk&quot; REAL,<br>  &quot;has_geotechnical_risk_land_settlement&quot; INTEGER,<br>  &quot;has_geotechnical_risk_fault_crack&quot; INTEGER,<br>  &quot;has_geotechnical_risk_liquefaction&quot; INTEGER,<br>  &quot;has_geotechnical_risk_landslide&quot; INTEGER,<br>  &quot;has_geotechnical_risk_rock_fall&quot; INTEGER,<br>  &quot;has_geotechnical_risk_flood&quot; INTEGER,<br>  &quot;has_geotechnical_risk_other&quot; INTEGER<br>)</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>index</td>\n",
       "            <td>ix_building_damage_building_id</td>\n",
       "            <td>building_damage</td>\n",
       "            <td>12305</td>\n",
       "            <td>CREATE INDEX &quot;ix_building_damage_building_id&quot;ON &quot;building_damage&quot; (&quot;building_id&quot;)</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>table</td>\n",
       "            <td>household_demographics</td>\n",
       "            <td>household_demographics</td>\n",
       "            <td>30763</td>\n",
       "            <td>CREATE TABLE &quot;household_demographics&quot; (<br>&quot;household_id&quot; INTEGER,<br>  &quot;gender_household_head&quot; TEXT,<br>  &quot;age_household_head&quot; REAL,<br>  &quot;caste_household&quot; TEXT,<br>  &quot;education_level_household_head&quot; TEXT,<br>  &quot;income_level_household&quot; TEXT,<br>  &quot;size_household&quot; REAL,<br>  &quot;is_bank_account_present_in_household&quot; REAL<br>)</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>index</td>\n",
       "            <td>ix_household_demographics_household_id</td>\n",
       "            <td>household_demographics</td>\n",
       "            <td>30764</td>\n",
       "            <td>CREATE INDEX &quot;ix_household_demographics_household_id&quot;ON &quot;household_demographics&quot; (&quot;household_id&quot;)</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('table', 'id_map', 'id_map', 2, 'CREATE TABLE \"id_map\" (\\n\"household_id\" INTEGER,\\n  \"building_id\" INTEGER,\\n  \"vdcmun_id\" INTEGER,\\n  \"district_id\" INTEGER\\n)'),\n",
       " ('index', 'ix_id_map_household_id', 'id_map', 3, 'CREATE INDEX \"ix_id_map_household_id\"ON \"id_map\" (\"household_id\")'),\n",
       " ('table', 'building_structure', 'building_structure', 2032, 'CREATE TABLE \"building_structure\" (\\n\"building_id\" INTEGER,\\n  \"count_floors_pre_eq\" INTEGER,\\n  \"count_floors_post_eq\" INTEGER,\\n  \"age_building\" IN ... (198 characters truncated) ... or_type\" TEXT,\\n  \"other_floor_type\" TEXT,\\n  \"position\" TEXT,\\n  \"plan_configuration\" TEXT,\\n  \"condition_post_eq\" TEXT,\\n  \"superstructure\" TEXT\\n)'),\n",
       " ('index', 'ix_building_structure_building_id', 'building_structure', 2033, 'CREATE INDEX \"ix_building_structure_building_id\"ON \"building_structure\" (\"building_id\")'),\n",
       " ('table', 'building_damage', 'building_damage', 12302, 'CREATE TABLE \"building_damage\" (\\n\"building_id\" INTEGER,\\n  \"damage_overall_collapse\" TEXT,\\n  \"damage_overall_leaning\" TEXT,\\n  \"damage_overall_adja ... (2923 characters truncated) ... ndslide\" INTEGER,\\n  \"has_geotechnical_risk_rock_fall\" INTEGER,\\n  \"has_geotechnical_risk_flood\" INTEGER,\\n  \"has_geotechnical_risk_other\" INTEGER\\n)'),\n",
       " ('index', 'ix_building_damage_building_id', 'building_damage', 12305, 'CREATE INDEX \"ix_building_damage_building_id\"ON \"building_damage\" (\"building_id\")'),\n",
       " ('table', 'household_demographics', 'household_demographics', 30763, 'CREATE TABLE \"household_demographics\" (\\n\"household_id\" INTEGER,\\n  \"gender_household_head\" TEXT,\\n  \"age_household_head\" REAL,\\n  \"caste_household\"  ... (8 characters truncated) ...  \"education_level_household_head\" TEXT,\\n  \"income_level_household\" TEXT,\\n  \"size_household\" REAL,\\n  \"is_bank_account_present_in_household\" REAL\\n)'),\n",
       " ('index', 'ix_household_demographics_household_id', 'household_demographics', 30764, 'CREATE INDEX \"ix_household_demographics_household_id\"ON \"household_demographics\" (\"household_id\")')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM sqlite_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71808ee9",
   "metadata": {},
   "source": [
    "Selects rows from the column `name` in which the `type` column as the value `table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d9666b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2798651751.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mSELECT name\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# prints the names of the tables in the database\n",
    "%%sql\n",
    "SELECT name\n",
    "FROM sqlite_schema\n",
    "WHERE type = \"table\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d966912",
   "metadata": {},
   "source": [
    "Determines the unique values in the `district_id` column from table `id_map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT distinct(district_id)\n",
    "FROM id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b8238",
   "metadata": {},
   "source": [
    "Calculates the number of observations in the `id_map` table associated with district `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47703098",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT count(*)\n",
    "FROM id_map\n",
    "WHERE district_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951210b6",
   "metadata": {},
   "source": [
    "Calculates the number of observations in the `id_map` table associated with district `3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ff23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT count(*)\n",
    "FROM id_map\n",
    "WHERE district_id = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e437cf",
   "metadata": {},
   "source": [
    "Joins the unique building IDs from Kavrepalanchok in `id_map`, all the columns from `building_structure`, and the `damage_grade` column from `building_damage`. \n",
    "\n",
    "Renames the `building_id` column in `id_map` to `b_id` and limits the results to the first five rows of the new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0468597",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT distinct(i.building_id) as b_id,\n",
    "  s.*,\n",
    "  d.damage_grade\n",
    "FROM id_map as i\n",
    "JOIN building_structure as s ON i.building_id = s.building_id\n",
    "JOIN building_damage as d ON i.building_id = d.building_id\n",
    "WHERE district_id = 3\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262176f",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e77412",
   "metadata": {},
   "source": [
    "Builds a wrangle function that uses the query created to create a DataFrame. \n",
    "\n",
    "In addition, the function also:\n",
    "\n",
    "- Creates a `severe_damage` column, where all buildings with a damage grade greater than 3 should be encoded as 1. All other buildings should be encoded at 0.\n",
    "- Drops columns that could cause issues with leakage or multicollinearity in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(db_path):\n",
    "    # Connects to database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Constructs query\n",
    "    query = '''\n",
    "    SELECT distinct(i.building_id) as b_id,\n",
    "      s.*,\n",
    "      d.damage_grade\n",
    "    FROM id_map as i\n",
    "    JOIN building_structure as s ON i.building_id = s.building_id\n",
    "    JOIN building_damage as d ON i.building_id = d.building_id\n",
    "    WHERE district_id = 3\n",
    "    '''\n",
    "    \n",
    "    # Reads query results into DataFrame\n",
    "    df = pd.read_sql(query, conn, index_col=\"b_id\")\n",
    "\n",
    "    # Identifies leaky columns (data gathered after earthquake)\n",
    "    drop_cols = [col for col in df.columns if \"post_eq\" in col]\n",
    "\n",
    "    # Adds high-cardinality / redundant column\n",
    "    drop_cols.append(\"building_id\")\n",
    "\n",
    "    # Creates binary target column\n",
    "    df[\"damage_grade\"] = df[\"damage_grade\"].str[-1].astype(int)\n",
    "    df[\"severe_damage\"] = (df[\"damage_grade\"] > 3).astype(int)\n",
    "\n",
    "    # Drops old target\n",
    "    drop_cols.append(\"damage_grade\")\n",
    "\n",
    "    # Drops multicollinearity column\n",
    "    drop_cols.append(\"count_floors_pre_eq\")\n",
    "    \n",
    "    # Drops columns\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102eff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/nepal.sqlite\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586aeb61",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29c276",
   "metadata": {},
   "source": [
    "Creates a bar chart with the normalized value counts from the `severe_damage` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() \n",
    "\n",
    "# Calculate value counts and plot on the axes object\n",
    "df[\"severe_damage\"].value_counts(normalize=True).plot(\n",
    "    kind=\"bar\",\n",
    "    ax=ax  # Direct the plot to our Axes object\n",
    ")\n",
    "\n",
    "# Set labels and title \n",
    "ax.set_xlabel(\"Severe Damage\")\n",
    "ax.set_ylabel(\"Relative Frequency\")\n",
    "ax.set_title(\"Kavrepalanchok, Class Balance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393803ee",
   "metadata": {},
   "source": [
    "Uses seaborn to create a boxplot that shows the distributions of the `plinth_area_sq_ft` column for both groups in the `severe_damage` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() \n",
    "\n",
    "# Create the Seaborn boxplot \n",
    "sns.boxplot(x=\"severe_damage\", y=\"plinth_area_sq_ft\", data=df, ax=ax)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(\"Severe Damage\")\n",
    "ax.set_ylabel(\"Plinth Area [sq. ft.]\")\n",
    "ax.set_title(\"Kavrepalanchok, Plinth Area vs Building Damage\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48bfab",
   "metadata": {},
   "source": [
    "Creates a pivot table of `df` where the index is `roof_type` and the values come from the `severe_damage` column, aggregated by the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9250c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "roof_pivot = pd.pivot_table(\n",
    "    df, index=\"roof_type\", values=\"severe_damage\", aggfunc=np.mean\n",
    ").sort_values(by=\"severe_damage\")\n",
    "roof_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f872d54",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732eb38f",
   "metadata": {},
   "source": [
    "Creates the feature matrix `X` and target vector `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ee21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"severe_damage\")\n",
    "y = df[\"severe_damage\"]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6289fcc",
   "metadata": {},
   "source": [
    "<font size=\"+1\"><strong>Validation Data Split</strong></font>\n",
    "\n",
    "Validation datasets are usually used to tune model hyperparameters.\n",
    "\n",
    "A hyperparameter is a model setting that can't be learned during model training and must be explicitly set. In contrast, a model parameter can be learned. An example of a hyperparameter is the depth of a decision tree. \n",
    "\n",
    "An example of a model parameter includes a coefficient of a variable from linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d948e",
   "metadata": {},
   "source": [
    "Divides the dataset into training and validation sets using a randomized split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb979ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f2cae",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4ea18",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120ca2d",
   "metadata": {},
   "source": [
    "Here the baseline model is represented as if we predicted `severe_damage == 1` for every test datapoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_baseline = y_train.value_counts(normalize=True)\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf47e56",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47477efc",
   "metadata": {},
   "source": [
    "The logistic regression model is the classifier version of linear regression. It will predict probability values that can be used to assign class labels. \n",
    "\n",
    "The model works by taking the output of a linear regression model and feeding it into a sigmoid or logistic function. \n",
    "\n",
    "The sigmoid function bounds predictions between 0 and 1, which we then treat as a probability. This allows us to use the model forÂ classificationÂ problems.\n",
    "\n",
    "<code><strong>OneHotEncoder</strong></code>\n",
    "\n",
    "A property's district is categorical data. \n",
    "\n",
    "For many machine learning algorithms, it's common to create a column in a DataFrame to indicate if the feature is present or absent, instead of using the category's name. \n",
    "\n",
    "It is necessary so the model can be able to separate the contribution of each category and calculate its coefficients:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc583e",
   "metadata": {},
   "source": [
    "### Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4570bb",
   "metadata": {},
   "source": [
    "Creates the model `model_lr` that uses logistic regression to predict building damage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd829e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = make_pipeline(\n",
    "    OneHotEncoder(use_cat_names=True),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1cd69b",
   "metadata": {},
   "source": [
    "Calculates training and validation accuracy score for `model_lr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_acc = accuracy_score(y_train, model_lr.predict(X_train))\n",
    "lr_val_acc = model_lr.score(X_val, y_val)\n",
    "\n",
    "print(\"Logistic Regression, Training Accuracy Score:\", lr_train_acc)\n",
    "print(\"Logistic Regression, Validation Accuracy Score:\", lr_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ed5a64",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f387be",
   "metadata": {},
   "source": [
    "Decision trees are a general class of machine learning models that are used for both classification and regression. \n",
    "\n",
    "The model resemble a tree, complete with branches and leaves. The model is essentially a series of questions with \"yes\" or \"no\" answers. \n",
    "\n",
    "The decision tree starts by checking whatever condition does the best job at correctly separating the data into the two classes in the binary target. It then progressively checks more conditions until it can predict an observation's label. \n",
    "\n",
    "They are popular because they are more flexible than linear models and intuitive in a way that makes them easy to explain to stakeholders who are not familiar with data science.\n",
    "\n",
    "We start at the root in a place of dataset impurity and our goal is to divide this set into categories constantly increasing pureness in the data.\n",
    "\n",
    "Decision trees pros and cons:\n",
    "\n",
    "| Pros | Cons | \n",
    "| --- | --- | \n",
    "| can be used for classification and regression | generalization: they are prone to overfitting |\n",
    "| handles both numerical and categorical data | robustness: small variations in data can result in a different tree |\n",
    "| models nonlinear relationships between the features and target | class imbalance: if one class is much larger than the other, the tree may be unbalanced |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee3687",
   "metadata": {},
   "source": [
    "<code><strong>Ordinal Encoder</strong></code>\n",
    "\n",
    "Two primary issues that can arise using `OneHotEncoder` as the number of features grows: computational complexity (operations performed on larger datasets may take longer) and overfitting (the model may not generalize to new data).\n",
    "\n",
    "Ordinal encoding is a popular choice for encoding the categorical variable. Instead of creating new columns, ordinal encoding simply replaces the categories in a categorical variable with integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2259b1c",
   "metadata": {},
   "source": [
    "### Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1e297",
   "metadata": {},
   "source": [
    "Creates a `for` loop to train and evaluate the model `model_dt` at all depths from 1 to 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b20a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_hyperparams = range(1, 16)\n",
    "training_acc = []\n",
    "validation_acc = []\n",
    "for d in depth_hyperparams:\n",
    "    model_dt = make_pipeline(\n",
    "        OrdinalEncoder(),\n",
    "        DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    )\n",
    "    model_dt.fit(X_train, y_train)\n",
    "    training_acc.append(model_dt.score(X_train, y_train))\n",
    "    validation_acc.append(model_dt.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(validation_acc, index=depth_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56a810",
   "metadata": {},
   "source": [
    "Plots the validation curve for `model_dt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea30a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() \n",
    "\n",
    "#  Plot the training accuracy on the axes object\n",
    "ax.plot(depth_hyperparams, training_acc, label=\"training\")\n",
    "\n",
    "#  Plot the validation accuracy on the same axes object\n",
    "ax.plot(depth_hyperparams, validation_acc, label=\"validation\") \n",
    "\n",
    "#  Set labels and title  \n",
    "ax.set_xlabel(\"Max Depth\")\n",
    "ax.set_ylabel(\"Accuracy Score\")\n",
    "ax.set_title(\"Validation Curve, Decision Tree Model\")\n",
    "\n",
    "# Add the legend \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64272",
   "metadata": {},
   "source": [
    "Builds and trains a new decision tree model `final_model_dt`, using the value for `max_depth` that yielded the best validation accuracy score in the above plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d28add",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_dt = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    ").fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef58834",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f9903",
   "metadata": {},
   "source": [
    "Reads the CSV file with the test set into a DataFrame. \n",
    "\n",
    "Next, uses `final_model_dt` to generate a list of test predictions `y_test_pred`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d320926",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"data/kavrepalanchok-test-features.csv\", index_col=\"b_id\")\n",
    "y_test_pred = final_model_dt.predict(X_test[X_train.columns])\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca0ad0",
   "metadata": {},
   "source": [
    "## Communicate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c927bd",
   "metadata": {},
   "source": [
    "Creates a Series Gini `feat_imp` sorted from smallest to largest feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "importances = final_model_dt.named_steps[\"decisiontreeclassifier\"].feature_importances_\n",
    "\n",
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "feat_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c3ad6",
   "metadata": {},
   "source": [
    "Creates a horizontal bar chart of `feat_imp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0048f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() \n",
    "\n",
    "# Create the horizontal bar plot on the axes object\n",
    "feat_imp.plot(kind=\"barh\", ax=ax)\n",
    "\n",
    "# Set labels and title \n",
    "ax.set_xlabel(\"Gini Importance\")\n",
    "ax.set_ylabel(\"Feature\")\n",
    "ax.set_title(\"Kavrepalanchok Decision Tree, Feature Importance\")\n",
    "\n",
    "# Apply tight layout \n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
