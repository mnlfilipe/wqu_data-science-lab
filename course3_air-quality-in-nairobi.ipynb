{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc26ddde",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>3 Air Quality in Nairobi üá∞üá™</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c843b20",
   "metadata": {},
   "source": [
    "<font size=\"+2\"><strong>3.5 Air Quality in Dar es Salaam üáπüáø</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68a4c3",
   "metadata": {},
   "source": [
    "This notebook resumes the most important things learned in the WorldQuant course 3 Applied Data Science Lab - Air Quality in Nairobi\". It uses the courses' project \"Air Quality in Dar es Salaam\" since it implements the main ideas learned.\n",
    "\n",
    "In this project, we''ll work with data from one of Africa's largest open data platforms openAfrica. We'll also look at air quality data from Nairobi, Lagos, and Dar es Salaam; and build a time series model to predict PM 2.5 readings throughout the day.\n",
    "\n",
    "Topics learned in this project:\n",
    "\n",
    "- How to get data by querying a MongoDB database.\n",
    "- How to prepare time series data for analysis.\n",
    "- How to build an autoregression model.\n",
    "- How to improve a model by tuning its hyperparameters.\n",
    "\n",
    "<div style=\"display: inline-block; max-width: 950px; padding: 1em; border: 1px solid #f0ad4e; border-left: 6px solid #f0ad4e; background-color: #fcf8e3; color: #8a6d3b; border-radius: 4px;\">\n",
    "\n",
    "<strong>‚ö†Ô∏è Note:</strong> Since I don't have access to the MongoDB database (it is stored in the course virtual machine), I can't sucessfully run this code.\n",
    "\n",
    "To overcome this challenge the outputs were hardcoded (written) into this notebook.\n",
    "\n",
    "</div>\n",
    "\n",
    "Imports necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771aa018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from pymongo import MongoClient\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.ar_model import AutoReg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c32ff9",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadbabbb",
   "metadata": {},
   "source": [
    "## Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc368f0",
   "metadata": {},
   "source": [
    "Establishes the IP address on the MongoDB server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"192.129.29.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de234c01",
   "metadata": {},
   "source": [
    "MongoDB data is organized in the following hierarchical order: \n",
    "1. database:\n",
    "    - a MongDB server can host multiple databases\n",
    "    - they have to be accessed through a Client\n",
    "    \n",
    "2. collection:\n",
    "    - a collection stores a group of documents\n",
    "    - contains semi-structured data, this means different documents can have different features\n",
    "    \n",
    "3. document:\n",
    "    - basic unit of data in MongoDB\n",
    "    - stored in BSON (Binary JSON), which supports more types than JSON (e.g., dates, binary data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c6cbb",
   "metadata": {},
   "source": [
    "`PrettyPrinter` makes the information MongoDB generates easier to understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "\n",
    "pp = PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connects with DataBase\n",
    "client = MongoClient(host=host, port=27017)\n",
    "\n",
    "# lists databases available ion the server\n",
    "pp.pprint(list(client.list_databases()))\n",
    "\n",
    "# gets database\n",
    "db = client[\"air-quality\"]\n",
    "\n",
    "# lists collections available in 'db'\n",
    "db.list_collections()\n",
    "\n",
    "# assigns the 'dar-es-salaam' collection to a variable\n",
    "dar = db[\"dar-es-salaam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a1859",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6964162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks how many documents are in the 'dar' collection\n",
    "dar.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0cac8",
   "metadata": {},
   "source": [
    "233262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines how many sensor sites are included in the 'dar' collection\n",
    "sites = dar.distinct(\"metadata.site\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cce11e",
   "metadata": {},
   "source": [
    "[23, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043cb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines how many readings there are for each site in the¬†'dar'¬†collection\n",
    "dar.count_documents({\"metadata.site\": 11}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0e604",
   "metadata": {},
   "source": [
    "173242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e56353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines how many readings there are for each site in the¬†nairobi¬†collection\n",
    "result = dar.aggregate(\n",
    "    [\n",
    "        {\"$group\": {\"_id\": \"$metadata.site\", \"count\": {\"$count\": {}}}}\n",
    "    ]\n",
    ")\n",
    "\n",
    "readings_per_site = list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77ff5f",
   "metadata": {},
   "source": [
    "[{'_id': 23, 'count': 60020}, {'_id': 11, 'count': 173242}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90032ba8",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06117ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrives one random document from the 'dar' collection\n",
    "# a document is stored as a dictionary\n",
    "dar.find_one({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5881e93",
   "metadata": {},
   "source": [
    "<code>{'timestamp': datetime.datetime(2018, 1, 1, 0, 0, 48, 41000),  \n",
    "'metadata': {'lat': -6.818,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;'lon': 39.285,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;'measurement': 'temperature',  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;'sensor_id': 34,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;'sensor_type': 'DHT22',  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;'site': 11},  \n",
    " 'temperature': 30.1,  \n",
    " '_id': ObjectId('6525d778f44bfedd842c72d8')}</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065e888",
   "metadata": {},
   "source": [
    "### TimeSeries\n",
    "\n",
    "- MongoDB stores all timestamps in UTC\n",
    "- in this <code>wrangle</code> function the time data is converted to Africa/Dar_es_Salaam timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(collection):\n",
    "    \n",
    "    # Retrives the PM2.5 readings from site 11\n",
    "    # Uses the projection argument to limit the results to the \"P2\"¬†and¬†\"timestamp\"¬†keys only\n",
    "    result = collection.find(\n",
    "        {\"metadata.site\": 11, \"metadata.measurement\": \"P2\"},\n",
    "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},\n",
    "    )\n",
    "    \n",
    "    # Read results into DataFrame\n",
    "    df = pd.DataFrame(list(result)).set_index(\"timestamp\")\n",
    "\n",
    "    # Localize timezone\n",
    "    df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Dar_es_Salaam\")\n",
    "\n",
    "    # Remove outliers w/ readings above 100\n",
    "    df = df[df[\"P2\"] < 101]\n",
    "\n",
    "    # Resamples to 1-hour window mean values\n",
    "    # Imputes missing values using the forward-fill method\n",
    "    df = df[\"P2\"].resample(\"1H\").mean().fillna(method=\"ffill\").to_frame()\n",
    "\n",
    "    # squeeze() method converts 1-column DataFrame into a Series\n",
    "    return df.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423caa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wrangle(dar)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd707d68",
   "metadata": {},
   "source": [
    "<class 'pandas.core.series.Series'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bbf332",
   "metadata": {},
   "source": [
    "## Explore Some More"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fe71d",
   "metadata": {},
   "source": [
    "Creates a time series plot of the readings in <code>y</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# use ax=ax in your plot\n",
    "y.plot(ax=ax, xlabel=\"Date\", ylabel=\"PM2.5 Level\", title=\"Dar es Salaam PM2.5 Levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c8d12",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.36.44.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc0349",
   "metadata": {},
   "source": [
    "### Rolling Windows\n",
    "\n",
    "Rolling window is an important concept for time series analysis. We first define a window size, like 7 days, three months, etc. \n",
    "\n",
    "Then we calculate some statistics taking data from each window sequentially throughout the time series.\n",
    "\n",
    "Rolling window statistics are very helpful in smoothing noisy data when making time series predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7178f8",
   "metadata": {},
   "source": [
    "Plots the rolling average of the readings in <code>y</code>. \n",
    "\n",
    "Uses a window size of 168 (the number of hours in a week):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c23356",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# use ax=ax in your plot\n",
    "y.rolling(168).mean().plot(\n",
    "    ax=ax, \n",
    "    xlabel=\"Date\", \n",
    "    ylabel=\"PM2.5 Level\", \n",
    "    title=\"Dar es Salaam PM2.5 Levels, 7-Day Rolling Average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a1445",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.37.06.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d3815",
   "metadata": {},
   "source": [
    "ACT and PACT plots help understand the correlation between y and previous values of y. \n",
    "\n",
    "We want to compare our ACF and PACF plots to see which model best describes our time series. \n",
    "\n",
    "If the ACF data drops off slowly, then that's going to be a better description; if the PACF falls off slowly, then that's going to be a better description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c0367",
   "metadata": {},
   "source": [
    "### ACF Plot\n",
    "\n",
    "An Autocorrelation Function (ACF) plot is created so we can see how autocorrelations change over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047fa0ba",
   "metadata": {},
   "source": [
    "Creates an ACF plot for the data in <code>y</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Use ax=ax in your plot\n",
    "\n",
    "plot_pacf(y, ax=ax);\n",
    "\n",
    "ax.set_xlabel(\"Lag [hours]\")\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "ax.set_title(\"Dar es Salaam PM2.5 Readings, PACF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5d460",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.37.23.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f1704",
   "metadata": {},
   "source": [
    "### PACF\n",
    "\n",
    "The Partial ACF (PACF) takes into account the echo between values.\n",
    "\n",
    "It should be used to determine which previous values of y should be used in the predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd1a59",
   "metadata": {},
   "source": [
    "Creates an PACF plot for the data in <code>y</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c8322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# use ax=ax in your plot\n",
    "plot_acf(y, ax=ax);\n",
    "\n",
    "ax.set_xlabel(\"Lag [hours]\")\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "\n",
    "ax.set_title(\"Dar es Salaam PM2.5 Readings, ACF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c59d3",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.37.36.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422afa3d",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40280b3",
   "metadata": {},
   "source": [
    "Splits <code>y</code> into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9999b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_test = int(0.9 * len(y))\n",
    "y_train = y.iloc[:cutoff_test]\n",
    "y_test = y.iloc[cutoff_test:]\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7c653",
   "metadata": {},
   "source": [
    "y_train shape: (1944,)  \n",
    "y_test shape: (216,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e959d",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a1612",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfc31a",
   "metadata": {},
   "source": [
    "Establishes the baseline mean absolute error for the model.\n",
    "\n",
    "The baseline MEA is considers a model where the prediction is always the mean value of the training predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mean = y_train.mean()\n",
    "y_pred_baseline = [y_train_mean] * len(y_train)\n",
    "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
    "\n",
    "print(\"Mean P2 Reading:\", y_train_mean)\n",
    "print(\"Baseline MAE:\", mae_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e739c",
   "metadata": {},
   "source": [
    "Mean P2 Reading: 8.57142319061077  \n",
    "Baseline MAE: 4.053101181299159"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b88b0",
   "metadata": {},
   "source": [
    "## Model Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32601885",
   "metadata": {},
   "source": [
    "### Autoregression Models\n",
    "\n",
    "Autoregression (AR) is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. \n",
    "\n",
    "AR works in a similar way to autocorrelation: in both cases, we're taking data from one part of a set and comparing it to another part. An AR model regresses itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84473929",
   "metadata": {},
   "source": [
    "### ARMA Models\n",
    "\n",
    "ARMA stands for Auto Regressive Moving Average, and it's a special kind of time-series analysis. \n",
    "\n",
    "AR models rely on values that remain relatively stable over time. That is, they can predict the future very well, as long as the future looks roughly the same as the past. \n",
    "\n",
    "The trouble with predicting the future is that things can suddenly change, and as a result, the future doesn't look much like the past anymore. \n",
    "\n",
    "These sudden changes can be as big as a hurricane destroying a city or an unexpected increase in the minimum wage, and they can be as small as a new restaurant opening in a neighborhood or a single person losing their job. \n",
    "\n",
    "In our data, the air quality might be changed if there was a nearby forest fire, or if a building collapsed near one of the sensors and raised a giant cloud of dust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f4822",
   "metadata": {},
   "source": [
    "## Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e2e72",
   "metadata": {},
   "source": [
    "### Lags\n",
    "\n",
    "Lagging data means that we're adding a delay. In this case, we're going to allow the model to test itself out by comparing its predictions for different hour lags. \n",
    "\n",
    "If the prediction and the reality are close, then it's a good model; if they aren't, then the model isn't a very good one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a823f2a",
   "metadata": {},
   "source": [
    "The following code aims to determine which hyperparameter setting will give me the best performance.\n",
    "\n",
    "To predict PM2.5 readings, it uses an AutoReg model.\n",
    "\n",
    "The <code>for</code> loop is used to train the AR model on using settings for lags from 1 to 30. \n",
    "\n",
    "Each time a new model is trained, it calculates its MEA and appends the result to a list.\n",
    "\n",
    "The results are stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range to test different lags\n",
    "p_params = range(1, 31)\n",
    "\n",
    "# Create empty list to hold mean absolute error scores\n",
    "maes = []\n",
    "\n",
    "# Iterate through all values of p in `p_params`\n",
    "for p in p_params:\n",
    "    # Build model\n",
    "    model = AutoReg(y_train.copy(), lags=p).fit()\n",
    "\n",
    "    # Make predictions on training data, dropping null values caused by lag\n",
    "    y_pred = model.predict().dropna()\n",
    "\n",
    "    # Calculate mean absolute error for training data vs predictions\n",
    "    mae = mean_absolute_error(y_train.iloc[p:], y_pred)\n",
    "\n",
    "    # Append `mae` to list `maes`\n",
    "    maes.append(mae)\n",
    "\n",
    "# Put list `maes` into Series with index `p_params`\n",
    "mae_series = pd.Series(maes, name=\"mae\", index=p_params)\n",
    "\n",
    "# Inspect head of Series\n",
    "mae_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c6403",
   "metadata": {},
   "source": [
    "1&nbsp;&nbsp;&nbsp;&nbsp;1.059376  \n",
    "2&nbsp;&nbsp;&nbsp;&nbsp;1.045182  \n",
    "3&nbsp;&nbsp;&nbsp;&nbsp;1.032489  \n",
    "4&nbsp;&nbsp;&nbsp;&nbsp;1.032147  \n",
    "5&nbsp;&nbsp;&nbsp;&nbsp;1.031022  \n",
    "Name: mae, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134f2c2",
   "metadata": {},
   "source": [
    "Determines which value for <code>p</code> provides the best performance.\n",
    "\n",
    "Build a model for that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p = min(mae_series.index, key=mae_series.get)\n",
    "best_model = AutoReg(y_train, lags=best_p).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c18002",
   "metadata": {},
   "source": [
    "### Residuals\n",
    "\n",
    "<code>y_train_resid = y_train - y_pred</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0acbd3",
   "metadata": {},
   "source": [
    "Calculates the training residuals for <code>best_model</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad992788",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resid = best_model.resid\n",
    "y_train_resid.name = \"residuals\"\n",
    "y_train_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cccd1b",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.40.53.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00ba1c",
   "metadata": {},
   "source": [
    "Creates a histogram of <code>y_train_resid</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of residuals\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Use ax=ax in your plot\n",
    "y_train_resid.hist(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Residuals\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Best Model, Training Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c77e10",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.41.12.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4f87d",
   "metadata": {},
   "source": [
    "Creates an ACF plot for <code>y_train_resid</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Use ax=ax in your plot\n",
    "plot_acf(y_train_resid, ax=ax);\n",
    "ax.set_xlabel(\"Lag [hours]\")\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "ax.set_title(\"Dar es Salaam, Training Residuals ACF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f2b8b",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.41.24.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a17249",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c2902",
   "metadata": {},
   "source": [
    "### Walk-forward Validation\n",
    "\n",
    "Our predictions lose power over time because the model gets farther and farther away from its beginning. \n",
    "\n",
    "But what if we could move that beginning forward with the model? That's what **walk-forward validation** is. \n",
    "\n",
    "In a walk-forward validation, we re-train the model at for each new observation in the dataset, dropping the data that's the farthest in the past. \n",
    "\n",
    "Let's say that our prediction for what's going to happen at 12:00 is based on what happened at 11:00, 10:00, and 9:00. \n",
    "\n",
    "When we move forward an hour to predict what's going to happen at 1:00, we only use data from 10:00, 11:00, and 12:00, dropping the data from 9:00 because it's now too far in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a715e",
   "metadata": {},
   "source": [
    "Performs walk-forward validation for the model for the entire test set <code>y_test</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wfv = pd.Series()\n",
    "history = y_train.copy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    model = AutoReg(history, lags=26).fit()\n",
    "    next_pred=model.forecast()\n",
    "    y_pred_wfv=y_pred_wfv.append(next_pred)\n",
    "    history=history.append(y_test[next_pred.index])\n",
    "y_pred_wfv.name = \"prediction\"\n",
    "y_pred_wfv.index.name = \"timestamp\"\n",
    "y_pred_wfv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97641422",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.41.33.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6a89f",
   "metadata": {},
   "source": [
    "Calculates MAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = mean_absolute_error(y_test, y_pred_wfv)\n",
    "print(\"Test MAE (walk forward validation):\", round(test_mae, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f8171",
   "metadata": {},
   "source": [
    "# Commmunicate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65d613",
   "metadata": {},
   "source": [
    "Plots <code>df_pred_test</code> using plotly express:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21057776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame({\"y_test\": y_test, \"y_pred_wfv\": y_pred_wfv}, index=y_test.index)\n",
    "fig = px.line(df_pred_test)\n",
    "fig.update_layout(\n",
    "    title=\"Dar es Salaam, WFV Predictions\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"PM2.5 Level\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f200252",
   "metadata": {},
   "source": [
    "<img src=\"images/Screenshot%202025-08-27%20at%2017.41.44.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ae1ca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
